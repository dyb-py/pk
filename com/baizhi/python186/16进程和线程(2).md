# 进程和线程

~~~markdown
进程和线程，是属于Python的并发库

任务调度
1. 一般是采用时间片轮转抢占式调度方式
		CPU---计算（多核，一个核心可以同时执行1个进程）
		OS----操作系统（最高权限）
		人的反应速度：0.02秒  20ms--200ms
		计算机中，程序运行的资源是时间片
		时间片：一小段时间---操作系统
		由操作系统，给各个进程进行时间分配
		小结： OS定期的抛出时间片资源，各个进程争抢时间片，抢占到时间片的进程，可以正常执行，当时间片到期，该程序则会暂停运行，等待下一个时间片的抛出
		1. 任务正在执行的状态：运行状态
		2. 任务等待时间片的状态：阻塞状态
2. CPU的切换频率很高，在高频切换下，可以执行多个任务，让人类感觉是多个程序同时执行
		本质，任务之间高速切换	

~~~

* 进程和线程

~~~markdown
进程：
1. 进程是一个具有一定独立功能的程序，在一个数据集合上的一次动态执行过程，是操作系统进行资源分配和调度的独立单位，是应用程序运行的载体
		进程是一种过程
		进程和进程之间相互独立， 互不干扰
2. 进程是一个抽象的概念，没有统一的概念，进程的结构：
		1. 程序
		2. 数据集合
		3. 程序控制块（PCB）
3. 进程和进程之间相互独立， 互不干扰
4. 进程的特性：
		1. 动态性
		2. 并发性
		3. 独立性
		4. 结构性
		
cpu：运算器+寄存器+控制器

线程：
1. 轻量级的进程
		早期没有线程的概念
2. 线程的上下文切换速度远远快于进程
		线程的执行效率高
3. 一个进程可以有多个线程，各个线程之间共享进程的资源
4. 线程的结构：
		1. 线程ID
		2. 指令指针
		3. 寄存器
		4. 堆栈
5. 线程也是抽象的概念
6. 线程是程序执行的最小单位，也是操作系统分配资源的最小单位
		操作系统不直接给线程分配资源，通过进程间接分配
7. 单线程和多线程
		单线程：
			在运行过程中，多个线程执行时，每一次只能执行一个线程，执行完一个线程之后，才可以执行下一个线程
		多线程：
			在运行过程中，多个线程执行时，可以同时执行多个线程，围观上：每个线程都执行一部分，多个线程同时进行
~~~

* 线程模块threading

~~~markdown
在单核CPU下
***微观串行，宏观并行***

在多核CPU下
可以实现真正的并发

CPython：官方提供的，标准Python
GIL：Global Interpreter Lock  
	全局解释锁
一般情况：
单核模式
1. 一个CPU核心可以执行一个进程
2. 在同一个进程下，可以由多个线程：
		微观串行，宏观并行
多核模式
1. 多个进程可以被多个CPU核心运行
2. 不同进程中的线程，可以并发执行
		真正并发
		
CPython的情况：
单核模式
1. 一个CPU核心可以执行一个进程
2. 在同一个进程下，可以由多个线程：
		微观串行，宏观并行
多核模式
1. 多个进程可以被多个CPU核心运行
2. 不同进程中的线程，因为有GIL锁的出现，每次只能执行一个线程
		微观串行，宏观并行

GIL：
1. 几乎让多线程，成为单线程
		原因：GIL锁标记抛出到重新获取的时间间隙短，其他线程来不及抢资源---大概率一个线程或大量获取所标记---几乎相当于单线程执行
2. 在多核模式下，大大降低CPU使用率
		原因：GIL锁标记抛出，触发CPU核心的激活，在激活和休眠的过程中损失大量资源
3. GIL锁保证系统中每次只有一个线程进行执行，保证数据安全
~~~

* 线程的创建

~~~markdown
1. 直接使用threading模块中的Thread（构造参数）
		使用Thread类的构造方法创建线程
		__init__(self, group=None, target=None, name=None,
                 args=(), kwargs=None, *, daemon=None)
         group:预留参数
         target：目标对象（要执行的目标）
         name：设置线程的名字
         args：目标对象需要的参数（位置参数）---元组
         kwargs:目标对象需要的参数（关键字参数）---字典
         daemon:设置线程是否为守护线程         
~~~

~~~python
import threading

def music(name,n):
    for i in range(n):
        print('听音乐%s第%s次'%(name,i))

def movie(name,n):
    for i in range(n):
        print('看电影%s第%s次'%(name,i))

if __name__ == '__main__':
    t1=threading.Thread(target=music,args=('野狼Disco',10)) # 泛函编程，函数式编程
    t2=threading.Thread(target=movie,args=('哪吒',10))

    t1.start()
    t2.start()
~~~

~~~markdown
2. 创建Thread类的子类（派生类），覆盖run（）方法，将要执行的内容写到run方法中
~~~

~~~python
class Music(threading.Thread):
    def __init__(self,name,n):
        # 要调用父类的init方法
        super().__init__()  # 只能写在第一行
        self.name=name
        self.n=n

    def run(self):
        for i in range(self.n):
            print('听音乐%s第%s次'%(self.name,i))


class Movie(threading.Thread):
    def __init__(self,name,n):
        # 要调用父类的init方法
        super().__init__()  # 只能写在第一行
        self.name=name
        self.n=n

    def run(self):
        for i in range(self.n):
            print('看电影%s第%s次'%(self.name,i))

if __name__ == '__main__':
    t1=Music('野狼Disco',10)
    t2=Movie('哪吒',10)

    t1.start()
    t2.start()
~~~

* 创建线程的方法

~~~markdown
1. 直接使用Thread的构造方法
2. 创建Thread的子类，覆盖run方法
~~~

* 线程对象的方法

~~~markdown
1. getName()/name
		返回线程的名字
		线程的名字默认：Thread-n
2. setName(name)
		设置线程名称
3. ident
		获取线程id（线程号）
		线程号在启动之后才会被创建
4. is_alive()/isAlive()
		判断线程是否存活
5. join（[timeout]）
		timeout:超时的秒数
		阻塞当前线程，先执行调用join（）的线程，
			如果没有设置timeout，先执行的线程执行完毕之后才可以继续执行当前线程
			如果设置了timeout,限制性的线程在制定时间内没有执行完毕，强制解开阻塞，执行当前线程
		
		例如：A.join()在主线程中运行的，此时阻塞主线程，先运行A线程，直到A线程执行完毕，再执行主线程
6. daemon：
		设置指定线程为守护线程（精灵线程）
		如果一个线程是守护线程，当主线程停止时，所有的守护线程会被杀死
		Python中典型的守护线程：垃圾回收机制			
~~~

---

~~~markdown
pose机   10个人  每个人每次只能刷1元钱   每天最多刷500次   10个人向同一个银行卡刷钱  模拟一天的刷卡操作 
~~~

---

* 子线程，主线程

~~~markdown
1. 子线程：
		手工创建的线程(Thread)
2. 主线程：
		主界面运行的main函数（当前运行的线程），UI界面
		一般主线程是不需要手工创建的
~~~

* 线程的状态

![]()

---

* GIL全局解释锁

~~~markdown
1. GIL锁： 是CPython的引入的，但是不是Python的特性
		其他的语言（解释器）也可以由GIL锁
		Python的其他的解释器，没有GIL
2. 单核模式下：效率不会降低，多核模式下：效率会大大降低
		多核模式下：GIL将多线程几乎变为了单线程
3. GIL锁标记抛出到重新获取的时间间隔短
4. GIL锁是降低CPU的效率：
5. Python的多线程应用场景
		1. I/O密集型程序使用多线程
		2. CPU密集型程序使用多进程		
~~~

* 线程同步

~~~markdown
数据安全
污染---全局变量---数据脏读

1. 原子操作
		不可以拆分的操作（业务不可拆分）
2. 临界资源
		可以同时被多个线程访问的资源（数据）
3. 数据不安全：
		1. 原子操作遭到破坏
		2. 多个线程访问同一个临界资源（临界资源是不安全）

4. 解决办法：
		加锁：
		线程锁，排他锁，互斥锁
		Lock对象
		注意： 临界资源是不安全的，原子操作控制的临界资源，锁要加给原子操作
5. 原子操作加了锁：
		优点：数据安全
		缺点：效率低
~~~

~~~python
import threading
import time

l=['A','B','','']
index=2  # 1. 有效元素个数  2. 即将修改的下标
lock=threading.Lock()  # 创建锁对象
# 创建目标函数
def fun(s):
    global index
    # 加锁
    lock.acquire()
    l[index]=s
    time.sleep(0.00003)
    index+=1
    lock.release()
# 创建线程对象，调用构造方法，传入参数： target=目标函数名 args=（参数列表）
if __name__ == '__main__':  # 测试
    t1=threading.Thread(target=fun,args=('C',))
    t2=threading.Thread(target=fun,args=('D',))
    # 调用start（） 启动线程
    t1.start()
    t2.start()
    t1.join()
    t2.join()
    print(l)
~~~

* 死锁

~~~markdown
1. 如果原子操作被同时加了多把锁，此时该原子操作，产生死锁
2. 解决：
		可重入锁
		Rlock对象
~~~

~~~python
import threading
import time

l=['A','B','','']
index=2  # 1. 有效元素个数  2. 即将修改的下标
lock=threading.Lock()  # 创建锁对象
rlock=threading.RLock() #可重入锁对象
# 创建目标函数
def fun(s):
    global index
    # 加锁
    rlock.acquire()
    rlock.acquire()
    l[index]=s
    time.sleep(0.00003)
    index+=1
    rlock.release()
    rlock.release()
# 创建线程对象，调用构造方法，传入参数： target=目标函数名 args=（参数列表）
if __name__ == '__main__':  # 测试
    t1=threading.Thread(target=fun,args=('C',))
    t2=threading.Thread(target=fun,args=('D',))
    # 调用start（） 启动线程
    t1.start()
    t2.start()
    t1.join()
    t2.join()
    print(l)
~~~

---

* ThreadLocal对象---线程绑定对象

~~~markdown
1. 访问临界资源：
		1. 如果是全局变量，全局共享，所有的线程都可以访问，不安全，但是全局只有一个，占用资源较少
		2. 如果是局部变量，每个线程独自拥有，数据是安全的，但是每个线程会额外创建新的变量，占用资源较多
2. ThreadLocal对象：
		在全局进行定义，在局部进行使用
		具有全局变量的通用性，同时还具有局部变量的安全性
		调用：threading.local()
~~~

~~~python
import threading,time

# money=100  # 全局变量是不安全的，消耗资源较少
local=threading.local()  # 创建ThreadLocal对象
class A:pass
a=A()

def fun(money):
    # money=100 #局部变量安全，但是过于消耗资源
    local.money=money    #在线程绑定对象中创建了一个实例属性
    a.hehe=money
    for i in range(10):
        time.sleep(0.01)
        # money-=1
        print('余额为%s'%local.money,'当前线程为：%s'%threading.currentThread().name)
        print('hehe值为：%s'%a.hehe)

if __name__ == '__main__':
    t1=threading.Thread(target=fun,args=(100,))
    t2=threading.Thread(target=fun,args=(200,))
    t1.start()
    t2.start()
~~~

---

### 多进程模块： multiprocessing

~~~markdown
1. 是多进程模块，大多数的方法名，沿用threading模块
2. 使用方式：类似于threading
		import multiprocessing
3. Process(),Pipe(),Queue,Lock
		Process对象中：start()，join(),run()...
4. Process(self,group,target:,name,args:,kwargs:,daemon:)
		group:预留参数
		target:目标，类，方法，函数，对象
		args:target的参数，是一个可迭代对象
		kwargs：具有映射关系的对象（字典）
		daemon：设置守护进程
5. 进程对象常用方法和属性:
		terminate():终止进程
		join(),阻塞当前进行，优先执行调用该方法的进程
		is_alive()：判断是否是运行状态
		name：返回进程名称：Process-n
		daemon:设置进程是否为守护进程
~~~

~~~python
import multiprocessing

count=0
def fun():
    global count
    count+=1
    print(count,multiprocessing.current_process().name)

if __name__ == '__main__':
    p1=multiprocessing.Process(target=fun)  # 进程和进程之间相互独立，互不干扰
    p2=multiprocessing.Process(target=fun)
    p3=multiprocessing.Process(target=fun)

    print(p1.name)
    print(p1.is_alive())
    print(p1.daemon)

    p1.start()
    print(p1.is_alive())
    print(p1.ident)
    p2.start()
    p3.start()
    p1.terminate()
    p1.join()
    p2.join()
    p3.join()

    print('hehe')
~~~

* 多进程模块的对象

~~~markdown
Pool：进程池对象
Pipe：管道对象
Queue：队列对象
~~~

* Pool进程池

~~~markdown
1. 池：
		1. 存放多个数据
		2. 批量生产数据
		3. 数据存储 ： 常量池，串池。。。
2. 进程池：
		批量创建进程
3. 进程池对象的方法：
		1. apply（func，[args,[kwds]]）
			阻塞的执行，进程池中的进程
			执行效率低，不建议使用
		2. apply_async(fun,[args,[kwargs,[callback]]])
			非阻塞执行,进程池中的进程
			async：异步
			异步：
				执行效率高，不安全
				数据不同步，线程不同步，同一个资源，多个线程可以同时访问
			同步：
				数据同步，线程同步，加锁
				执行效率低，安全
				数据是否同步（线程同步），同一个资源，多个线程只能有一个线程访问
		3. close（）：
				关闭pool对象，池中的进程继续执行，不再创建新的任务
		4. terminate()：
				关闭pools对象，池中的进程不再执行
		5. join（）:
				阻塞主进程，等待子进程执行完毕，才可以执行主进程
				join（）必须在close()或terminate（）之后使用
			join必须在关闭资源之后调用，避免永远无法关闭
~~~

~~~python
import multiprocessing,time
def fun(n):
    print(n)
    time.sleep(3)

if __name__ == '__main__':
    pool=multiprocessing.Pool(3)
    for i in range(10):
        pool.apply_async(func=fun,args=(i,))

    pool.close()
    pool.join()
    print('end')
~~~

* Queue队列对象

~~~markdown
1. 队列是先进先出
2. 线程安全的队列
3. Queue(maxsize)
		maxsize：设置队列的容量
4. 队列对象中的方法
		1. put（obj,block=True,timeout=None）：
				把obj插入到队列中
				如果队列已满：
				如果block为True，并且timeout设置了时间，该方法会阻塞指定的时间，直到时间到了则报错，itmeout=None，继续等待
				如果block为False，直接报错（Queue.Full）
		2. get（block=True, timeout=None）
				从队列中读取并删除数据
				block：是否验证时间
				timeout:设置等待时间
				如果队列为空：
				如果block为True，并设置了时间，等待指定时间，如果不为空，取出指定数据，如果还为空，继续等待
				如果block为False，只要空了，直接报错
		3. get_nowait(): get(block=False)
		4. put_nowait(): put(block=False)
		5. empty():
				判断队列是否为空
				不可靠
		6. full（）：
				判断队列是否已满
				不可靠
		7. qsize()：
				返回队列实际元素个数
				不可靠
5. 进程之间可以共享进程队列对象
		如果进程和进程之间想要通信，使用队列
~~~

~~~python
import multiprocessing,time

def putItems(q):
    for i in ['A','B','C']:
        print(multiprocessing.current_process().name,'向队列中插入一个数据%s'%i)
        q.put(i)
        time.sleep(1)

def getItems(q):
    while 1:
        value=q.get()
        print(multiprocessing.current_process().name,'从队列中获取到数据%s'%value)


if __name__ == '__main__':
    q = multiprocessing.Queue()  # 默认无限大
    p1=multiprocessing.Process(target=putItems,args=(q,))
    p2=multiprocessing.Process(target=getItems,args=(q,))

    p1.start()
    p2.start()
    p1.join()

    p2.terminate()
    print('结束')
~~~

* Pipe管道

~~~markdown
1. 进程安全的管道，管道的底层是由队列实现
2. Pipe(duplex):
		duplex:bool值
		返回一个元组，（conn1，conn2）代表管道的两端
		duplex:如果为True(默认)全双工模式，conn1和conn2都可以发送和接受数据
			   如果为False半双工模式，conn1只负责接收消息（从管道中取出消息），conn2只负责发送消息（向管道中放入消息）
3. send/recv
		send（message）:发送数据，到管道中
		recv（）:从管道中接受一个数据，如果调用了该方法，但是管道中没有任何数据，进入到阻塞状态，直到等到消息获得为止
		如果管道已经关闭，抛出异常EOFError
~~~

~~~python
import multiprocessing,time

def put(p): #p: (conn1,conn2)
    for i in ['A','B','C']:
        p[1].send(i)
        print('%s发送了消息%s'%(multiprocessing.current_process().name,i))
        time.sleep(1)
def get(p):
    while 1:
        value=p[0].recv()
        print('%s接收到了%s消息'%(multiprocessing.current_process().name,value))


if __name__ == '__main__':
    pipe=multiprocessing.Pipe(duplex=False)
    sendMessage=multiprocessing.Process(target=put,args=(pipe,))
    receiveMessage=multiprocessing.Process(target=get,args=(pipe,))

    sendMessage.start()
    receiveMessage.start()

    sendMessage.join()
    receiveMessage.terminate()

    print('执行结束')
~~~

* 生产者消费者模型

~~~markdown
1. 数据的产生和数据的使用，这个过程称之为生产者消费者模式
2. 有指定的程序构建数据，有指定的程序使用数据
		一边生产数据，一边消耗数据
3. 大多数的应用，程序，项目，是生产者消费者模型
4. 生产者也可以同时是消费者，消费者也可以是生产者
5. 模型：
		生产者生产数据，暂时存储到介质中
		消费者时刻的消费数据，将暂存的数据拿走，（暂存数据被删除）
		1. 暂存的数据总量不大，总传数量大（大量的数据，需要少量存储）
		2. 数据是动态的，数据不会永久存储
~~~

* 队列模拟生产者消费者模型

~~~markdown
1. multiprocessing.Queue()  对象  
		进程队列
2. queue.Queue():
		通用队列
~~~

~~~python
import queue,threading,time

count=0
def product(q,name):
    global count
    while 1:
        q.put('第%s辆汽车'%count)
        print('%s生产了%s'%(name,'第%s辆汽车'%count))
        count += 1
        time.sleep(1)

def consume(q,name):
    while 1:
        r=q.get()
        print('%s购买%s'%(name,r))
        time.sleep(0.2)


if __name__ == '__main__':

    q=queue.Queue()
    producer1=threading.Thread(target=product,args=(q,'老王'))
    consumer1=threading.Thread(target=consume,args=(q,'小波'))
    consumer2=threading.Thread(target=consume,args=(q,'建刚'))
    consumer3=threading.Thread(target=consume,args=(q,'刘浩'))

    producer1.start()
    consumer1.start()
    consumer2.start()
    consumer3.start()

    producer1.join()
~~~

---

